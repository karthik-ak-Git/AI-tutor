{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19396fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e8d5b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f15e2cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LLM initializing...\n",
      "‚úì LLM initialized (OpenAI: gpt-4.1-nano)\n",
      "content=\"Hello! I'm doing well, thank you. How about you? How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-4.1-nano', 'system_fingerprint': None, 'id': 'gen-1764336899-trrkcIImpGM1bJuRgv4r', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--b87f8efd-f0e0-4129-bcb0-9785c0ca11e9-0' usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"‚úì LLM initializing...\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-4.1-nano\",\n",
    "    openai_api_key=api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.5,\n",
    "    timeout=10\n",
    ")\n",
    "\n",
    "print(\"‚úì LLM initialized (OpenAI: gpt-4.1-nano)\")\n",
    "\n",
    "response = llm.invoke(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a537f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embedding model initialized (HuggingFace: all-MiniLM-L6-v2)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "print(\"‚úì Embedding model initialized (HuggingFace: all-MiniLM-L6-v2)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d438e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loading PDF: DSA Handwritten Notes.pdf\n",
      "‚úì Loaded 50 pages\n",
      "‚úì Split into 37 chunks\n",
      "‚úì Vector store created with 37 document chunks\n",
      "‚úì RAG pipeline ready!\n",
      "ü§ñ AI Tutor & Research Agent\n",
      "tags=['Chroma', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000020C141B34D0> search_kwargs={'k': 4}\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from pathlib import Path\n",
    "\n",
    "PDF_PATH = \"DSA Handwritten Notes.pdf\"\n",
    "\n",
    "if not Path(PDF_PATH).exists():\n",
    "    print(f\"‚ö† Warning: {PDF_PATH} not found.\")\n",
    "    vectorstore = None\n",
    "    retriever = None\n",
    "else:\n",
    "    print(f\"üìÑ Loading PDF: {PDF_PATH}\")\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    docs = loader.load()\n",
    "    print(f\"‚úì Loaded {len(docs)} pages\")\n",
    "\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    print(f\"‚úì Split into {len(splits)} chunks\")\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"k\": 4}\n",
    "    )\n",
    "\n",
    "    print(f\"‚úì Vector store created with {len(splits)} document chunks\")\n",
    "    print(\"‚úì RAG pipeline ready!\")\n",
    "\n",
    "RAG_RETRIEVER = retriever\n",
    "\n",
    "print(\"ü§ñ AI Tutor & Research Agent\")\n",
    "print(RAG_RETRIEVER)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84b41938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... what the capital of France is . ... Wait, if I can ‚Äô t look it up right now, but relying on my knowledge, yes, Paris is the capital of France . Besides Paris, what is the capital of France ? ... You use it between your head and your toes, the more it works the thinner it grows. What is the Capital of France ? ... As the capital city of France , the city plays host to the national government of France . However, Paris only became the official capital of France during the reign of Clovis I , in the late 5th and early 6th century. As the capital and largest city in France , it is one of Europe ‚Äô s major centers of finance, diplomacy, commerce, fashion, science and the arts.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "print(search_tool.invoke(\"What is the capital of France?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44770c0",
   "metadata": {},
   "source": [
    "that may cause you the error of ddgs if it try to install the ddgs with pip install ddgs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8019e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: Paris is the capital and most populous city of France ., title: Paris, France - Intercultural City - Intercultural Cities Programme, link: https://www.coe.int/en/web/interculturalcities/paris, snippet: Paris is the capital city of France , situated on the River Seine, in northern France , at the heart of the √éle-de- France region. The Paris \"aire urbaine\" is one of the most populated areas of its kind in Europe, with a population of roughly ..., title: Paris, France - New World Encyclopedia, link: https://www.newworldencyclopedia.org/entry/Paris,_France, snippet: Exact time now, time zone, time difference, sunrise/sunset time and key facts for Paris, France .Paris is the capital of France ., title: Time in Paris, France now, link: https://time.is/Paris, snippet: Exact time, time zone and time change dates in 2025 for Paris, France .Paris is the capital of France ., title: Current time in Paris, France, link: https://24timezones.com/Paris/time\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# 1. Configure the wrapper to ask for more results\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=25) \n",
    "\n",
    "# 2. Create the tool using this wrapper\n",
    "search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "\n",
    "# 3. Run the search\n",
    "results = search_tool.invoke(\"What is the capital of France?\")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02f427",
   "metadata": {},
   "source": [
    "that is multi result in single line \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d50652eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 4 results:\n",
      "\n",
      "Result 1:\n",
      "With 200,000 inhabitants in 1328, Paris, then already the capital of France , was the most populous city of Europe. By comparison, London in 1300 had 80,000 inhabitants.[29] By the early fourteenth ce...\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Paris is the capital and most populous city of France ., title: Paris, France - Intercultural City - Intercultural Cities Programme, link: https://www.coe.int/en/web/interculturalcities/paris...\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Paris is the capital city of France , situated on the River Seine, in northern France , at the heart of the √éle-de- France region. The Paris \"aire urbaine\" is one of the most populated areas of its ki...\n",
      "--------------------------------------------------\n",
      "Result 4:\n",
      "Exact time now, time zone, time difference, sunrise/sunset time and key facts for Paris, France .Paris is the capital of France ., title: Time in Paris, France now, link: https://time.is/Paris...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# 1. Setup the search for 25 results\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=25)\n",
    "search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "\n",
    "# 2. Get the raw string output (the messy part)\n",
    "raw_output = search_tool.invoke(\"What is the capital of France?\")\n",
    "\n",
    "# 3. Fix the Output: Convert the string into a real Python list\n",
    "# The output format typically looks like \"[snippet: ..., title: ..., link: ...], ...\"\n",
    "# We can use a custom parser since the default format is sometimes tricky.\n",
    "# But simpler method first:\n",
    "try:\n",
    "    # Try standard list parsing\n",
    "    results_list = ast.literal_eval(raw_output)\n",
    "except:\n",
    "    # Fallback: Manual splitting if ast fails (sometimes LangChain format is weird)\n",
    "    # This simple split works for the format you pasted\n",
    "    results_list = raw_output.split(\", snippet:\") \n",
    "\n",
    "print(f\"‚úÖ Found {len(results_list)} results:\\n\")\n",
    "\n",
    "# 4. Print them cleanly\n",
    "for i, item in enumerate(results_list, 1):\n",
    "    # Basic cleanup for display\n",
    "    clean_item = str(item).replace(\"snippet: \", \"\").replace(\"],\", \"\").strip()\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"{clean_item[:200]}...\") # Print first 200 chars only\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "428f80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Web search tool initialized (DuckDuckGo)\n",
      "‚úì Search tool ready for agent use\n"
     ]
    }
   ],
   "source": [
    "# Fix: Use the working DuckDuckGoSearchResults approach\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# Create search tool with multiple results\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=10)\n",
    "search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "\n",
    "print(\"‚úì Web search tool initialized (DuckDuckGo)\")\n",
    "print(\"‚úì Search tool ready for agent use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21621481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG retriever tool created\n",
      "‚úì Document search tool ready\n"
     ]
    }
   ],
   "source": [
    "# Create RAG Retriever Tool\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "if RAG_RETRIEVER is None:\n",
    "    print(\"‚ö† Warning: RAG retriever not available. Agent will only use web search.\")\n",
    "    retriever_tool = None\n",
    "else:\n",
    "    # Create RAG tool manually (compatible with all LangChain versions)\n",
    "    def search_document_func(query: str) -> str:\n",
    "        \"\"\"Search the uploaded PDF document for relevant information.\"\"\"\n",
    "        docs = RAG_RETRIEVER.get_relevant_documents(query)\n",
    "        if not docs:\n",
    "            return \"No relevant information found in the document.\"\n",
    "        \n",
    "        # Combine all retrieved chunks\n",
    "        result = \"\\n\\n\".join([f\"Excerpt {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
    "        return result\n",
    "    \n",
    "    # Create the tool\n",
    "    retriever_tool = Tool(\n",
    "        name=\"search_document\",\n",
    "        func=search_document_func,\n",
    "        description=\"Searches and returns relevant excerpts from the uploaded PDF document. \"\n",
    "        \"Use this tool when the user asks questions about the document, specific concepts \"\n",
    "        \"mentioned in the document, or requests explanations based on the document content.\"\n",
    "    )\n",
    "    print(\"‚úì RAG retriever tool created\")\n",
    "    print(\"‚úì Document search tool ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e1594d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Preparing 2 tools for agent\n",
      "‚úì Memory initialized\n",
      "‚úì AI Tutor Agent initialized successfully!\n",
      "\n",
      "ü§ñ Agent Capabilities:\n",
      "  ‚Ä¢ Answer questions from uploaded documents (RAG)\n",
      "  ‚Ä¢ Search the web for real-time information\n",
      "  ‚Ä¢ Remember conversation context\n",
      "  ‚Ä¢ Route queries intelligently\n"
     ]
    }
   ],
   "source": [
    "# Initialize Agent with Memory (Compatible approach - Custom Memory)\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Prepare tools list\n",
    "tools = [search_tool]\n",
    "if retriever_tool is not None:\n",
    "    tools.append(retriever_tool)\n",
    "\n",
    "print(f\"‚úì Preparing {len(tools)} tools for agent\")\n",
    "\n",
    "# Simple custom memory class (no external dependencies)\n",
    "class SimpleMemory:\n",
    "    \"\"\"Simple conversation memory that stores messages.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_user_message(self, content):\n",
    "        \"\"\"Add a user message to memory.\"\"\"\n",
    "        self.messages.append(HumanMessage(content=content))\n",
    "    \n",
    "    def add_ai_message(self, content):\n",
    "        \"\"\"Add an AI message to memory.\"\"\"\n",
    "        self.messages.append(AIMessage(content=content))\n",
    "    \n",
    "    def get_messages(self, last_n=None):\n",
    "        \"\"\"Get messages, optionally limited to last N.\"\"\"\n",
    "        if last_n:\n",
    "            return self.messages[-last_n:]\n",
    "        return self.messages\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear all messages.\"\"\"\n",
    "        self.messages = []\n",
    "\n",
    "# Initialize Memory\n",
    "memory = SimpleMemory()\n",
    "\n",
    "print(\"‚úì Memory initialized\")\n",
    "\n",
    "# Create a simple agent function that uses tools\n",
    "def agent_executor(input_dict):\n",
    "    \"\"\"Simple agent that routes to appropriate tool.\"\"\"\n",
    "    query = input_dict.get(\"input\", \"\")\n",
    "    chat_history = input_dict.get(\"chat_history\", [])\n",
    "    \n",
    "    # Build context from chat history\n",
    "    history_text = \"\"\n",
    "    if chat_history:\n",
    "        for msg in chat_history[-4:]:  # Last 4 messages for context\n",
    "            if hasattr(msg, 'content'):\n",
    "                role = \"Human\" if msg.__class__.__name__ == \"HumanMessage\" else \"Assistant\"\n",
    "                history_text += f\"{role}: {msg.content}\\n\"\n",
    "    \n",
    "    # Determine which tool to use based on query\n",
    "    # Simple heuristic: if query mentions \"document\" or \"PDF\" or RAG is available, use document search\n",
    "    use_document = retriever_tool is not None and (\n",
    "        \"document\" in query.lower() or \n",
    "        \"pdf\" in query.lower() or \n",
    "        \"note\" in query.lower() or\n",
    "        \"lecture\" in query.lower()\n",
    "    )\n",
    "    \n",
    "    # Get response from appropriate tool\n",
    "    if use_document:\n",
    "        tool_result = retriever_tool.invoke(query)\n",
    "        context = f\"Document Information:\\n{tool_result}\\n\\n\"\n",
    "    else:\n",
    "        # Use web search\n",
    "        tool_result = search_tool.invoke(query)\n",
    "        context = f\"Web Search Results:\\n{tool_result}\\n\\n\"\n",
    "    \n",
    "    # Create prompt with context\n",
    "    full_prompt = f\"\"\"You are a helpful AI tutor and research assistant.\n",
    "\n",
    "Previous conversation:\n",
    "{history_text}\n",
    "\n",
    "Current query: {query}\n",
    "\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Based on the information above, provide a clear, helpful answer. If the information doesn't fully answer the question, say so and provide what you can.\"\"\"\n",
    "    \n",
    "    # Get LLM response\n",
    "    response = llm.invoke(full_prompt)\n",
    "    return {\"output\": response.content}\n",
    "\n",
    "# Create agent as a runnable\n",
    "agent = RunnableLambda(agent_executor)\n",
    "\n",
    "print(\"‚úì AI Tutor Agent initialized successfully!\")\n",
    "print(\"\\nü§ñ Agent Capabilities:\")\n",
    "print(\"  ‚Ä¢ Answer questions from uploaded documents (RAG)\")\n",
    "print(\"  ‚Ä¢ Search the web for real-time information\")\n",
    "print(\"  ‚Ä¢ Remember conversation context\")\n",
    "print(\"  ‚Ä¢ Route queries intelligently\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f7cf24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chat function ready\n",
      "üí° Run: chat_with_tutor() to start interactive session\n"
     ]
    }
   ],
   "source": [
    "# Interactive Chat Interface\n",
    "def chat_with_tutor():\n",
    "    \"\"\"\n",
    "    Interactive chat loop with the AI Tutor.\n",
    "    The agent automatically routes queries to the appropriate tool.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ü§ñ AI Tutor & Research Agent\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nI can help you with:\")\n",
    "    print(\"  ‚Ä¢ Questions about your uploaded document (RAG)\")\n",
    "    print(\"  ‚Ä¢ General knowledge and current events (Web Search)\")\n",
    "    print(\"  ‚Ä¢ Explanations and tutoring (Combined knowledge)\")\n",
    "    print(\"\\nType 'quit', 'exit', or 'bye' to end the session.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_query = input(\"\\nüë§ You: \").strip()\n",
    "            \n",
    "            # Check for exit commands\n",
    "            if user_query.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "                print(\"\\nüëã Goodbye! Happy learning!\")\n",
    "                break\n",
    "            \n",
    "            if not user_query:\n",
    "                print(\"Please enter a question or type 'quit' to exit.\")\n",
    "                continue\n",
    "            \n",
    "            # Get agent response\n",
    "            print(\"\\nü§ñ Tutor: \")\n",
    "            response = agent.invoke({\n",
    "                \"input\": user_query,\n",
    "                \"chat_history\": memory.get_messages()\n",
    "            })\n",
    "            \n",
    "            # Save to memory\n",
    "            output_text = response.get(\"output\", \"\") if isinstance(response, dict) else str(response)\n",
    "            memory.add_user_message(user_query)\n",
    "            memory.add_ai_message(output_text)\n",
    "            \n",
    "            # Display response\n",
    "            if isinstance(response, dict) and \"output\" in response:\n",
    "                print(response[\"output\"])\n",
    "            else:\n",
    "                print(str(response))\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Session interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"Please try rephrasing your question or check your connection.\")\n",
    "\n",
    "print(\"‚úì Chat function ready\")\n",
    "print(\"üí° Run: chat_with_tutor() to start interactive session\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b77ac6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Test queries ready (uncomment to run)\n"
     ]
    }
   ],
   "source": [
    "# Quick Test - Single Query\n",
    "# Uncomment and modify the query to test the agent\n",
    "\n",
    "# Test 1: Document question (uses RAG if document is loaded)\n",
    "# if RAG_RETRIEVER is not None:\n",
    "#     print(\"üìö Test 1: Document Question\")\n",
    "#     response1 = agent.invoke({\n",
    "#         \"input\": \"What are the main topics covered in the document?\",\n",
    "#         \"chat_history\": []\n",
    "#     })\n",
    "#     print(f\"\\nResponse: {response1.get('output', response1) if isinstance(response1, dict) else response1}\\n\")\n",
    "\n",
    "# Test 2: Web search question\n",
    "# print(\"üåê Test 2: Web Search Question\")\n",
    "# response2 = agent.invoke({\n",
    "#     \"input\": \"What is the capital of France?\",\n",
    "#     \"chat_history\": []\n",
    "# })\n",
    "# print(f\"\\nResponse: {response2.get('output', response2) if isinstance(response2, dict) else response2}\\n\")\n",
    "\n",
    "# Test 3: Combined question (uses memory + tools)\n",
    "# print(\"üí¨ Test 3: Follow-up Question (Uses Memory)\")\n",
    "# response3 = agent.invoke({\n",
    "#     \"input\": \"Can you explain that in simpler terms?\",\n",
    "#     \"chat_history\": memory.get_messages()\n",
    "# })\n",
    "# print(f\"\\nResponse: {response3.get('output', response3) if isinstance(response3, dict) else response3}\")\n",
    "\n",
    "print(\"‚úì Test queries ready (uncomment to run)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3ff1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utility functions ready\n",
      "  ‚Ä¢ get_document_summary() - Get document summary\n",
      "  ‚Ä¢ clear_memory() - Clear conversation memory\n",
      "  ‚Ä¢ get_agent_status() - Show agent status\n"
     ]
    }
   ],
   "source": [
    "# Utility Functions\n",
    "def get_document_summary():\n",
    "    \"\"\"\n",
    "    Get a summary of the uploaded document using RAG.\n",
    "    \"\"\"\n",
    "    if RAG_RETRIEVER is None:\n",
    "        return \"No document loaded.\"\n",
    "    \n",
    "    # Retrieve relevant chunks\n",
    "    docs = RAG_RETRIEVER.get_relevant_documents(\"summary of main topics and key concepts\")\n",
    "    \n",
    "    # Use LLM to generate summary\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following document excerpts, provide a concise summary \n",
    "    of the main topics and key concepts:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"\n",
    "    Clear the conversation memory.\n",
    "    \"\"\"\n",
    "    memory.clear()\n",
    "    print(\"‚úì Conversation memory cleared\")\n",
    "\n",
    "def get_agent_status():\n",
    "    \"\"\"\n",
    "    Display current agent status and configuration.\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ AI Tutor Status:\")\n",
    "    print(f\"  ‚Ä¢ LLM: {llm.model_name}\")\n",
    "    print(f\"  ‚Ä¢ Embeddings: HuggingFace (all-MiniLM-L6-v2)\")\n",
    "    print(f\"  ‚Ä¢ RAG Available: {'Yes' if RAG_RETRIEVER is not None else 'No'}\")\n",
    "    print(f\"  ‚Ä¢ Tools: {len(tools)}\")\n",
    "    print(f\"  ‚Ä¢ Memory: Active\")\n",
    "\n",
    "print(\"‚úì Utility functions ready\")\n",
    "print(\"  ‚Ä¢ get_document_summary() - Get document summary\")\n",
    "print(\"  ‚Ä¢ clear_memory() - Clear conversation memory\")\n",
    "print(\"  ‚Ä¢ get_agent_status() - Show agent status\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfafb9",
   "metadata": {},
   "source": [
    "## üöÄ Ready to Use!\n",
    "\n",
    "**Quick Start:**\n",
    "1. Run all cells above to initialize the system\n",
    "2. Use `chat_with_tutor()` to start interactive session\n",
    "3. Or use `agent.run(\"your question\")` for single queries\n",
    "\n",
    "**Available Functions:**\n",
    "- `chat_with_tutor()` - Interactive chat interface\n",
    "- `get_document_summary()` - Get document summary\n",
    "- `clear_memory()` - Clear conversation memory\n",
    "- `get_agent_status()` - Show agent status\n",
    "\n",
    "**Tips:**\n",
    "- Ask questions about your document for RAG-based answers\n",
    "- Ask general questions for web search results\n",
    "- The agent remembers conversation context automatically\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
